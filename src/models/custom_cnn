import os
import json
import torch
import random
import numpy as np
from PIL import Image
from torchvision import transforms
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torch.optim import Adam

# -----------------------
# CONFIGURATION
# -----------------------
DATA_DIR = "data_dotplots"
TRAIN_JSON = os.path.join(DATA_DIR, "train.json")
VAL_JSON = os.path.join(DATA_DIR, "val.json")
TEST_JSON = os.path.join(DATA_DIR, "test.json")
BATCH_SIZE = 32
EPOCHS = 20
LR = 1e-3
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
SEED = 42

# -----------------------
# REPRODUCIBILITY
# -----------------------
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

# -----------------------
# DATASET
# -----------------------
class DotPlotDataset(Dataset):
    def __init__(self, json_file):
        with open(json_file, 'r') as f:
            self.data = json.load(f)
        self.transform = transforms.Compose([
            transforms.Grayscale(),
            transforms.Resize((128, 128)),
            transforms.ToTensor(),  # [0,1], shape: (1, 128, 128)
        ])

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        img = Image.open(item["dotplot"])
        img = self.transform(img)
        score = torch.tensor(item["score"], dtype=torch.float32)
        return img, score

# -----------------------
# MODEL
# -----------------------
class SmallCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(1, 16, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 64x64

            nn.Conv2d(16, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 32x32

            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 16x16
        )
        self.fc_layers = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 16 * 16, 128),
            nn.ReLU(),
            nn.Linear(128, 1)  # Regression output
        )

    def forward(self, x):
        x = self.conv_layers(x)
        return self.fc_layers(x)

# -----------------------
# TRAINING LOOP
# -----------------------
def train_model():
    # Load data
    train_loader = DataLoader(DotPlotDataset(TRAIN_JSON), batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(DotPlotDataset(VAL_JSON), batch_size=BATCH_SIZE)
    test_loader = DataLoader(DotPlotDataset(TEST_JSON), batch_size=BATCH_SIZE)

    model = SmallCNN().to(DEVICE)
    loss_fn = nn.MSELoss()
    optimizer = Adam(model.parameters(), lr=LR)

    for epoch in range(EPOCHS):
        model.train()
        train_loss = 0
        for x, y in train_loader:
            x, y = x.to(DEVICE), y.to(DEVICE).unsqueeze(1)
            pred = model(x)
            loss = loss_fn(pred, y)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * x.size(0)

        val_loss = 0
        model.eval()
        with torch.no_grad():
            for x, y in val_loader:
                x, y = x.to(DEVICE), y.to(DEVICE).unsqueeze(1)
                pred = model(x)
                val_loss += loss_fn(pred, y).item() * x.size(0)

        print(f"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss/len(train_loader.dataset):.4f} | "
              f"Val Loss: {val_loss/len(val_loader.dataset):.4f}")

    # Save model
    torch.save(model.state_dict(), "dotplot_cnn_regressor.pth")
    print("âœ… Model saved as dotplot_cnn_regressor.pth")

    # Final test evaluation
    test_model(model, test_loader, loss_fn)

# -----------------------
# TEST LOOP
# -----------------------
def test_model(model, test_loader, loss_fn):
    model.eval()
    test_loss = 0
    all_preds = []
    all_targets = []
    with torch.no_grad():
        for x, y in test_loader:
            x, y = x.to(DEVICE), y.to(DEVICE).unsqueeze(1)
            pred = model(x)
            test_loss += loss_fn(pred, y).item() * x.size(0)
            all_preds.extend(pred.cpu().numpy())
            all_targets.extend(y.cpu().numpy())

    print(f"ðŸ“Š Final Test MSE: {test_loss / len(test_loader.dataset):.4f}")

# -----------------------
# MAIN
# -----------------------
if __name__ == "__main__":
    train_model()